\documentclass[10pt,a4paper]{article}
\usepackage{amsmath}
\usepackage{amssymb}

\newcommand{\R}{ \mathbb R }
\newcommand{\E}{ \mathbb E }
\newenvironment{ejercicio}[3]
{
	\paragraph{Ejercicio #1}
	#2
	\paragraph{$D/.$}
	#3
	$\square$
}{
}


\begin{document}

\begin{ejercicio}{5}{
	Sea $f:[0,1] \to \R$ una funci\'on continua. Probar que
	$$
		\lim_{d\to\infty}
		\int_0^1 \dots \int_0^1
		f(
		\frac{
			x_1 + \dots + x_d
		}{d}
		)
		dx_1 \dots dx_d
		=
		f(\frac{1}{2})
	$$
}{
	Sean $(U_d)_{d \in \mathbb N}$ v.a.i.i.d. con distribucion uniforme en $[0,1]$

	Por ley de grandes numeros,
	$$
		\frac {U_1 + \dots + U_d}{d} \overset{P}{\to} \frac{1}{2}
	$$

	Como $f$ es continua,
	$$
		f(\frac {U_1 + \dots + U_d}{d}) \overset{P}{\to} f(\frac{1}{2})
	$$

	Por ser $f$ continua en el compacto $[0,1]$, $f([0,1])$ es acotada y, en particular, $f(\frac {U_1 + \dots + U_d}{d}) \subseteq f([0,1])$ estan acotados para todo $d \in \mathbb N$, luego
	$$
		f(\frac {U_1 + \dots + U_d}{d}) \overset{L^1}{\to} f(\frac{1}{2})
	$$


	Tomando esperanza a ambos lados queda el resultado pues $\E[f(\frac{1}{2})] = f(\frac{1}{2})$, y
	$\E[f(\frac {U_1 + \dots + U_d}{d})]
	=
	\int_0^1 \dots \int_0^1
	f(
	\frac{
		x_1 + \dots + x_d
	}{d}
	)
	dx_1 \dots dx_d$

}
\end{ejercicio}


\begin{ejercicio}{8a}{
	Probar que si $\Phi$ es convexa,
	$$
		\Phi(y) \ge \Phi(x) + \Phi'(x)(y-x)
	$$
	para todo $ x,y \in \R $
}{
	Sea $x \in \R$, considero el polinomio de taylor de $\Phi$ de grado 2 centrado en $x$, luego para todo $y \in \R$, existe $\xi$ tal que:
	$$
		\Phi(y) = \Phi(x) + \Phi'(x) (y-x) + \Phi''(\xi) \frac{(y-x)^2}{2}
	$$
	$\Phi(\xi) \ge 0$ por hipotesis, luego
	$$
		\Phi(y) \ge \Phi(x) + \Phi'(x) (y-x)
	$$
}
\end{ejercicio}

\begin{ejercicio}{8b}{
	Probar que 
	$$
		\Phi(\frac{x+y}{2}) \le \frac{1}{2}\Phi(x) + \frac{1}{2}\Phi(y)
	$$
	para todo $ x,y \in \R $
}{
	Aplicando el item anterior,
	$$
		\Phi(x) \ge \Phi(\frac{x+y}{2}) + \Phi'(\frac{x+y}{2}) \frac{x-y}{2}
	$$
	y
	$$
		\Phi(y) \ge \Phi(\frac{x+y}{2}) + \Phi'(\frac{x+y}{2}) \frac{y-x}{2}
	$$

	Sumando las desigualdades queda
	$$
		\Phi(x) + \Phi(y) \ge 2 \Phi(\frac{x+y}{2})
	$$
}
\end{ejercicio}

\begin{ejercicio}{8c}{
	$\Phi: \R^d \to \R$	se dice convexa si la matriz $(\Phi_{x_i x_j})$ es semidefinida positiva para todo $x \in \R^d$.
	Es decir, $\sum_{i=1}^n \sum_{j=1}^n \Phi_{x_i x_j} \xi_i \xi_j \ge 0$ para todo $\xi \in \R^d$.
	Probar que para tal $\Phi$,
	$$
		\Phi(y) \ge \Phi(x) + \nabla\Phi(x) \cdot (y-x)
	$$
	y
	$$
		\Phi(\frac{x+y}{2}) \le \frac{1}{2}\Phi(x) + \frac{1}{2}\Phi(y)
	$$
}{
	Considero el polinomio de Taylor
	$$
		\Phi(y) = \Phi(x)
		+ \sum_{i=1}^d \frac {\partial \Phi}{\partial x_i}(x) (y_i - x_i)
		+ \sum_{i=1}^d \sum_{j=1}^d \frac{\partial^2 \Phi}{\partial x_i \partial x_j}(x) (y_i - x_i) (y_j - x_j)
	$$

	el t\'ermino $\sum_{i=1}^d \sum_{j=1}^d \frac{\partial^2 \Phi}{\partial x_i \partial x_j}(x) (y_i - x_i) (y_j - x_j)$ es $\ge 0$ por hipotesis,

	y $\nabla\Phi(x) \cdot (y-x) = \sum_{i=1}^d \frac {\partial \Phi}{\partial x_i}(x) (y_i - x_i)$
}
\end{ejercicio}

\begin{ejercicio}{9}{
	Probar la desigualdad de Jensen
	$$
		\Phi(\E(X)) \le \E(\Phi(X))
	$$
	para toda variable aleatoria $X$ y $\Phi$ convexa
}{
	Supongamos $\E(X) < \infty$, y $\E (\Phi(X)) < \infty$.

		Vale $ \Phi(X) \ge \Phi(\E(X)) + \Phi'(\E(X))(X - \E(X)) $ c.s. :
		Pues fijando un $\omega \in \Omega$, por el ejercicio 8a,
		$$
			\Phi(X(\omega))
			\ge
			\Phi(\E(X)) + \Phi'(\E(X)) (X(\omega) - \E(X))
		$$

		Luego, por monotonÃ­a de la esperanza
		$$
			\E[\Phi(X(\omega))]
			\ge
			\E[\Phi(\E(X)) + \Phi'(\E(X)) (X(\omega) - \E(X))]
			$$$$
			=
			\Phi(\E(X)) + \Phi'(\E(X)) \E[X(\omega) - \E(X)]
			=
			\Phi(\E(X))
		$$
}\end{ejercicio}

\end{document}